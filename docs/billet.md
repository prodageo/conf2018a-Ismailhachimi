# Fonctionnement d'une IA conversationnelle

## Cartouche d'identification

 - Manifestation : CodeursEnSeine 2018
 - Lieu : Kindarena Rouen
 - Conférence : Fonctionnement d'une IA conversationnelle
 - Horaire de la conférence : 13h25 à 14h00
 - Durée de la conférence : 35 minutes
 - Conférencier(s) :
    - Arnold Zephir
        - Twitter : [@cepcap](https://twitter.com/cepcam)
    - FibreTigre
        - Twitter : [@FibreTigre](https://twitter.com/FibreTigre)
 - Audience : + 300 participants
 - Auteur du billet : Ismail EL HACHIMI
 - Mots-clés
    - IA conversationnelle
    - Réseau de neurones
    - Deep learning
    - LSTM
    - Variational Auto-Encoder
    - Python
    - Tensorflow
    - Raspberry PI
 - URL de l'illustration : ![CodeursEnSein2018](photo.jpg)

## Support
 - Lien vers le support (diapos) présenté en conférence : **N'est pas disponible**
 - Nombre de diapos du support : Entre 15 et 20
 - Plan du support : 
    1. Définition d'une IA conversationnelle et projet Yuri
    2. Le rôle des réseaux de neuronnes dans ce type d'IA
    3. Les maths derrière cette IA
    4. Les avantages et les inconvénients d'une IA conversationnelle
    5. Les éléments essentiels pour créer sa propre IA maison
    6. Des ressources pour réaliser une IA

## Résumé
Les solutions IA sont toujours en développement et ont eu une énorme évolution dû au développement Matériel (Capacité de Stockage et Unités de calculs) et Logicielle (Optimisation et calcul mathématique). Pour cela, les architectures de type réseaux de neuronnes sont devenues très développées ce qui a mené à bien produire par des chercheurs de nouvelles solutions pour y arriver à émitter les capacités cognitives de l'être humain. Cependant, cette capacité n'est toujours pas atteinte dû au capacité limités en sens de conscience artificielles que l'on arrive pas à émitter. En outre, nous arrivons quand même à utiliser ces architecture en remplaçant les systèmes dites "Rule-Based" ou tout simplement qui sont basées sur des règles par des réseaux de neuronnes. Les types fameux de ces réseaux de neuronnes sont les RNNs (réseaux de neuronnes réccurents) et CNNs (réseaux de neuronnes convolutifs). Avec ces types de réseaux de neuronnes, on peut concevoir des architectures qui permettent de réaliser des solutions "IA" conversationnelle qui peut mener une discussion.

En effet, ces solutions ne sont pas toujours performantes, dû à la contrainte de mémoire que les machines ne peuvent pas retenir au fil de temps après un nombre défini d'itérations ou d'étapes temporelles. Dans ce sens, nous pouvons constater qu'une contrainte d'`efficience` se pose et dans une recherche plus approfondie est encore nécessaire pour améliorer ces modèles dites IA conversationnelles. 

Par contre, l'avantage avec ce type d'IA (basé sur des algorithmes de machines learning) sont `portables` et donc, on peut continuer nos recherche dans ce sens sans avoir recommencer de zéro vu que les résultats sont éxploitable voire qu'une architecture IA conversationnelle peut être composé de plusieurs sous-IA qui permettent de rendre tout le pipeline de conversation, fonctionnel. C'est dans ce sens que les conférienciers nous ont expliqué que la recherche dans ce domaine évolue dans différents aspects. En effet, c'est devenu simple qu'une personne crée sa propre IA conversationnelle sans avoir une intervention technique d'un expert (Data Scientist) vu que nous pouvons reproduire des résultats publiés sur internet pas une personne qui l'a déjà fait. Donc, un autre avantage qui devient de plus en plus important, c'est que cette technologie devient de plus en plus `facile` à utiliser et surtout `extensible`.

## Architecture et facteur qualité

En terme de mesures de base au sens de l'ISO9126-4, le coût de ce type de solution est presque null vu que les codes sources sont accéssible sur internet. L'architecture de la solution, dépend fortement de l'environnement du développement ou de déloyment, vu qu'une IA peut être déployé sur Cloud, intégrée dans une solution comme guide ou service d'aide automatique ou sur les plateformes comme Facebook, Google ou tout simplement une solution en local en lançant le processus de machine learning sur sa propre machine. Toute architecture peut être testée et modifiée dû à la nature des résultats que nous pouvons obtenir avec les algorithmes de machine learning. Les facteurs de qualité les plus importants que l'on peut déduire de cette technologie sont la réutilisabilité, testabilité (vu qu'on peut publier nos application sur des plateformes reconnues avec un coût null sous quelques conditions de requêts client), et la portabilité (vu qu'on peut partager la solution en partageons l'architecture et les paramètres du modèle de machine learning associé).
